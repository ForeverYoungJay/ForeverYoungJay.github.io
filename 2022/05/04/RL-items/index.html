<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"foreveryoungjay.github.io","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_33328642&#x2F;article&#x2F;details&#x2F;123683755 non-stationray，sample efficiency，planning和Learnin，Reward，off-policy和on-policy Infinite horizon finite horizon Regretsnon-stationray：https:&#x2F;&#x2F;">
<meta property="og:type" content="article">
<meta property="og:title" content="RL items">
<meta property="og:url" content="https://foreveryoungjay.github.io/2022/05/04/RL-items/index.html">
<meta property="og:site_name" content="YANG JIYI">
<meta property="og:description" content="https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_33328642&#x2F;article&#x2F;details&#x2F;123683755 non-stationray，sample efficiency，planning和Learnin，Reward，off-policy和on-policy Infinite horizon finite horizon Regretsnon-stationray：https:&#x2F;&#x2F;">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://www.92python.com/uploads/allimg/200709/3-200F910433Sa.gif">
<meta property="article:published_time" content="2022-05-04T08:52:39.000Z">
<meta property="article:modified_time" content="2022-05-06T04:00:21.034Z">
<meta property="article:author" content="YANG JIYI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.92python.com/uploads/allimg/200709/3-200F910433Sa.gif">

<link rel="canonical" href="https://foreveryoungjay.github.io/2022/05/04/RL-items/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>RL items | YANG JIYI</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="YANG JIYI" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">YANG JIYI</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>
    
    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

    
    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://foreveryoungjay.github.io/2022/05/04/RL-items/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=4108565645,281447478&fm=26&gp=0.jpg">
      <meta itemprop="name" content="YANG JIYI">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YANG JIYI">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          RL items
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-05-04 17:52:39" itemprop="dateCreated datePublished" datetime="2022-05-04T17:52:39+09:00">2022-05-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-05-06 13:00:21" itemprop="dateModified" datetime="2022-05-06T13:00:21+09:00">2022-05-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_33328642/article/details/123683755">https://blog.csdn.net/qq_33328642/article/details/123683755</a></p>
<h1 id="non-stationray，sample-efficiency，planning和Learnin，Reward，off-policy和on-policy-Infinite-horizon-finite-horizon-Regrets"><a href="#non-stationray，sample-efficiency，planning和Learnin，Reward，off-policy和on-policy-Infinite-horizon-finite-horizon-Regrets" class="headerlink" title="non-stationray，sample efficiency，planning和Learnin，Reward，off-policy和on-policy Infinite horizon finite horizon Regrets"></a>non-stationray，sample efficiency，planning和Learnin，Reward，off-policy和on-policy Infinite horizon finite horizon Regrets</h1><p>non-stationray：<a target="_blank" rel="noopener" href="https://stepneverstop.github.io/rl-classification.html">https://stepneverstop.github.io/rl-classification.html</a></p>
<p>Stationary or not</p>
<p>根据环境十分稳定、可以将强化学习问题分为stationary、non-stationary。</p>
<p>如果状态转移<strong>和</strong>奖励函数是确定的，即选择动作aa后执行它的结果是确定的，那么这个环境就是stationary。</p>
<p>如果状态转移<strong>或</strong>奖励函数是不确定的，即选择动作aa后执行它的结果是不确定的，那么这个环境就是non-stationary。</p>
<p>A <a target="_blank" rel="noopener" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.516.4121&rep=rep1&type=pdf"><strong>stationary (平稳) policy</strong></a>, 𝜋𝑡πt, is a policy that does not change over time, that is, 𝜋𝑡=𝜋,∀𝑡≥0πt=π,∀t≥0, where 𝜋π can either be a function, 𝜋:𝑆→𝐴π:S→A (a deterministic (确定性) policy), or a conditional (条件) density, 𝜋(𝐴∣𝑆)π(A∣S) (a stochastic (随机) policy). A <strong>non-stationary policy</strong> is a policy that is <strong>not</strong> stationary (平稳) . More precisely, 𝜋𝑖πi may not be equal to 𝜋𝑗πj, for 𝑖≠𝑗≥0i≠j≥0, where 𝑖i and 𝑗j are thus two different time steps.</p>
<h1 id="强化学习的样本效率sample-efficiency：https-blog-csdn-net-wxc971231-article-details-120992949"><a href="#强化学习的样本效率sample-efficiency：https-blog-csdn-net-wxc971231-article-details-120992949" class="headerlink" title="强化学习的样本效率sample efficiency：https://blog.csdn.net/wxc971231/article/details/120992949"></a>强化学习的样本效率sample efficiency：<a target="_blank" rel="noopener" href="https://blog.csdn.net/wxc971231/article/details/120992949">https://blog.csdn.net/wxc971231/article/details/120992949</a></h1><p>horizon 这个词在各种强化学习教程里出现的频率不算高，但它也是要了解的一个概念。<br>先查词典：<br>n. 地平线；视野；眼界；范围</p>
<p>在强化学习里面，horizon主要取“范围”的含义。也可以理解为一个agent在environment里一步步走下去，在一次交互过程中，总共走过的步数。<br>举个例子，假设有一个“怎么玩都永远不会死”的游戏（只不过得分有高低罢了），那么把这个玩游戏的过程对应到强化学习领域，它就是一个无限步的概念，即 infinite horizon；反之则是 finite horizon（有限步）的。<br>在训练强化学习模型的时候，并不是说一个游戏非要玩到挂掉才行，我们也可以限定在一个固定的 horizon 内来计算reward。所以从这个角度来说，horizon 也可以认为是agent的生存时间，当agent的剩余可用步数改变的时候，那么agent的行为可能也就会随之改变。</p>
<p><a target="_blank" rel="noopener" href="https://www.guyuehome.com/36204">https://www.guyuehome.com/36204</a></p>
<p><a target="_blank" rel="noopener" href="https://www.92python.com/view/409.html">https://www.92python.com/view/409.html</a></p>
<p>计算累积奖励有两种方式，一种是计算从当前状态到结束状态的所有奖励值之和：</p>
<p>Gt=rt+1+rt+2+…+rt+T</p>
<p>上面适用于有限时界（Finite-horizon）情况下的强化学习，但是在有些无限时界（Finite-horizon）情况，智能体要执行的可能是一个时间持续很长的任务，比如自动驾驶，如果使用上式计算累积奖励值显然是不合理的。</p>
<p>需要一个有限的值，通常会增加一个折扣因子，如下式：<br><img src="https://www.92python.com/uploads/allimg/200709/3-200F910433Sa.gif" alt="img"></p>
<p>在上式中，0≤γ≤1 。当 γ 的值等于 0 时，则智能体只考虑下一步的回报；当 γ 的值越趋近于 1，未来的奖励就会被越多地考虑在内。需要注意的是，有时候我们会更关心眼下的奖励，有时候则会更关心未来的奖励，调整的方式就是修改 γ 的值。</p>
<h1 id="Regrets"><a href="#Regrets" class="headerlink" title="Regrets"></a>Regrets</h1><p>The action you regret the most is the one that should have been (more likely) used or taken. So the probability of taking this action is proportional to how deep you regret you haven’t taken it.</p>
<p>Mathematically speaking, the regret is expressed as the difference between the payoff (reward or return) of a possible action and the payoff of the action that has been actually taken. If we denote the payoff function as *<strong>u*</strong> the formula becomes:</p>
<p>*<strong>regret = u(possible action) - u(action taken)*</strong></p>
<p>Clearly we are interested in cases where the payoff of ‘**<em>possible action*<strong>’ outperforms the payoff of the ‘</strong></em>action taken***’, so we consider positive regrets and ignore zero and negative regrets.</p>
<p>As said earlier the probability of using an action other than the one actually used is proportional to the regret it generates.</p>
<p>For example if we took action a1 and got u(a1) = 1, then we computed u(a2)= 2, u(a3) = 4, u(a4) = 7. The respective regrets will be regret(a2) = u(a2) - u(a1) = 1, same for regret(a3) = 3, and regret(a4) = 6.<br>Total regrets is regret(a1) + regret(a2) + regret(a3) + regret(a4) = 0 + 1 + 3 + 6 = 10.</p>
<p>It is easy to see that the most regretted action is a4. To reflect this numerically, we update our strategy, denoted as σ, such as σ(a2) = 1/10 = .1, σ(a3) = 3/10 = .3, σ(a4) = 6/10 = .6.</p>
<p>Obviously, you might be asking, why not explicitly give action a4 a probability of 1 (σ(a4) = 1)? Simply because the notion of regret is used when facing another actor, such as in games. Playing in a deterministic manner in a game will give your opponent a chance to counter measure your strategy and win.</p>
<h1 id="Improving-Sample-Efficiency-In-Model-Free-Reinforcement-Learning-From-Imageshttps-blog-csdn-net-sufail-article-details-104889591"><a href="#Improving-Sample-Efficiency-In-Model-Free-Reinforcement-Learning-From-Imageshttps-blog-csdn-net-sufail-article-details-104889591" class="headerlink" title="Improving Sample Efficiency In Model-Free Reinforcement Learning From Imageshttps://blog.csdn.net/sufail/article/details/104889591"></a>Improving Sample Efficiency In Model-Free Reinforcement Learning From Images<a target="_blank" rel="noopener" href="https://blog.csdn.net/sufail/article/details/104889591">https://blog.csdn.net/sufail/article/details/104889591</a></h1><p>对<strong>事物</strong>进行感知、记忆、思考，叫做<strong>认知</strong>。</p>
<p>对<strong>认知</strong>进行感知、记忆、思考，叫做<strong>元认知</strong>。</p>
<p><strong>对认知进行认知，叫做元认知，对学习进行学习，可以理解为元学习。</strong></p>
<p>虽然可以用在线学习来进行强化学习，但是本质上，</p>
<p>在线学习 online learning=让机器用新鲜的数据流学习。</p>
<p>强化学习 reinforcement learning=让机器学习怎么样才能更好地学习。</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/02/20/%E3%80%90%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E3%80%91Deep-Q-Network-DQN-%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3/" rel="prev" title="【强化学习】Deep Q Network(DQN)算法详解">
      <i class="fa fa-chevron-left"></i> 【强化学习】Deep Q Network(DQN)算法详解
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/05/06/%E7%BD%AE%E4%BF%A1%E5%9F%9F%E7%AD%96%E7%95%A5%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E2%80%94%E2%80%94TRPO/" rel="next" title="置信域策略优化算法——TRPO">
      置信域策略优化算法——TRPO <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#non-stationray%EF%BC%8Csample-efficiency%EF%BC%8Cplanning%E5%92%8CLearnin%EF%BC%8CReward%EF%BC%8Coff-policy%E5%92%8Con-policy-Infinite-horizon-finite-horizon-Regrets"><span class="nav-number">1.</span> <span class="nav-text">non-stationray，sample efficiency，planning和Learnin，Reward，off-policy和on-policy Infinite horizon finite horizon Regrets</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%A0%B7%E6%9C%AC%E6%95%88%E7%8E%87sample-efficiency%EF%BC%9Ahttps-blog-csdn-net-wxc971231-article-details-120992949"><span class="nav-number">2.</span> <span class="nav-text">强化学习的样本效率sample efficiency：https:&#x2F;&#x2F;blog.csdn.net&#x2F;wxc971231&#x2F;article&#x2F;details&#x2F;120992949</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Regrets"><span class="nav-number">3.</span> <span class="nav-text">Regrets</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Improving-Sample-Efficiency-In-Model-Free-Reinforcement-Learning-From-Imageshttps-blog-csdn-net-sufail-article-details-104889591"><span class="nav-number">4.</span> <span class="nav-text">Improving Sample Efficiency In Model-Free Reinforcement Learning From Imageshttps:&#x2F;&#x2F;blog.csdn.net&#x2F;sufail&#x2F;article&#x2F;details&#x2F;104889591</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="YANG JIYI"
      src="https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=4108565645,281447478&fm=26&gp=0.jpg">
  <p class="site-author-name" itemprop="name">YANG JIYI</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">27</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/ForeverYoungJay" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;ForeverYoungJay" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yangjiyi19981211@gmail.com" title="E-Mail → mailto:yangjiyi19981211@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>
    
    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">YANG JIYI</span>
</div>
<br />
<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("12/11/2020 15:54:40");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "RUNING "+dnum+" DAY ";
        document.getElementById("times").innerHTML = hnum + " HOURS " + mnum + " MINS " + snum + " SECONDS";
    }
setInterval("createtime()",250);
</script>
        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

    </div>



<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/miku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true}});</script></body>
</html>
